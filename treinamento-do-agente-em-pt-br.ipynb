{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Treinamento do agente em Pt-br.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/DwarfThief/bbb9f7571a0e27049fb8ec72419f9796/treinamento-do-agente-em-pt-br.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duNKNx7vnYyw",
        "colab_type": "text"
      },
      "source": [
        " <h1>Treinamento do Agente em Português</h1>\n",
        "\n",
        " <h5>Desenvolvido por : Abílio Nogueira e Brenno Barbosa</h5>\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vZ66loGCArj",
        "colab_type": "text"
      },
      "source": [
        "<h2> Step 1 : Importanto e Instalando blibliotecas .</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_0ac4KGlsxV",
        "colab_type": "code",
        "outputId": "986be5ad-ca26-4278-95dc-d2d436a941dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import csv\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('rslp')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Hoyh_-Csac",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 2 : Adicionando base de dados..</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfpmx-8U_-C3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60176a49-9de7-43e0-a6d0-36eaada3f79c"
      },
      "source": [
        "with open(\"./baseDeTreino(PT-BR).csv\", 'r') as csvFile:\n",
        "  data_list = list(csv.reader(csvFile))\n",
        "  basetreinamento = []\n",
        "  i = 0\n",
        "  lista = 0\n",
        "  for row in data_list:\n",
        "      basetreinamento.append((row[0], row[1]))\n",
        "      lista = lista+1\n",
        "      i = i+1\n",
        "      if(i==50):\n",
        "          i = 0\n",
        "  csvFile.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('banco do brasil cobra restituicao de recursos de depositos judiciais do governo de minas', ' Negative')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjNbiRWME_bP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"./baseDeTeste(PT-BR).csv\", 'r') as csvFile:\n",
        "  data_list = list(csv.reader(csvFile))\n",
        "  baseteste = []\n",
        "  i = 0\n",
        "  lista = 0\n",
        "  for row in data_list:\n",
        "      baseteste.append((row[0], row[1]))\n",
        "      lista = lista+1\n",
        "      i = i+1\n",
        "      if(i==50):\n",
        "          i = 0\n",
        "  csvFile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGrLLUOGN6v",
        "colab_type": "code",
        "outputId": "f0f5ec4d-e2c8-4437-a469-9fe7f430ff72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(baseteste[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('bb e governo de minas travam disputa sobre depositos judiciais', ' Negative')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtGGeo5dHIcp",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 3:Removendo as stopwords.</h2>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rj0s8C_Jl1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords =set(stopwords.words('portuguese'))\n",
        "#Usamos o comando a baixo para adicionar outras stopwords para a lista já fornecida do nltk\n",
        "#stopwordsnltk.append('bb')\n",
        "def removendostopwords(texto):\n",
        "   frases=[]\n",
        "   for(palavras,emocao) in texto:\n",
        "      semstop = [palavra for palavra in palavras.split() if palavra not in stopwords]\n",
        "      frases.append((semstop,emocao))\n",
        "   return frases  \n",
        "  \n",
        "baseteste=removendostopwords(baseteste)\n",
        "basetreinamento=removendostopwords(basetreinamento)\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UJR89ogf_Ru",
        "colab_type": "code",
        "outputId": "ab7f46f3-3664-4df4-bc9a-0a3ead18e040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(baseteste[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['psol', 'vai', 'questionar', 'aumento', 'vereadores', 'prefeito', 'bh', 'justica', 'politica', 'estado', 'minas'], 'Negative')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HwXyd09Q6D3",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 4: Agora, vamos retirar o radical das palavras fazendo assim com que todas as palavras que deverivam da mesma ocupem apenas um espaço na lista.</h2>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8GWtsIpYu5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "  #Utiliza para apenas uma frase para realizar o teste\n",
        "def uniquestemmer(frase):\n",
        "  frasesteming = []\n",
        "  stemmer = nltk.stem.RSLPStemmer()\n",
        "  for(palavras) in frase.split():\n",
        "    comstem =[p for p in palavras.split()]\n",
        "    frasesteming.append(str(stemmer.stem(comstem[0])))\n",
        "  return frasesteming  \n",
        "#Realiza para todas as frases de uma base\n",
        "def aplicandostemmer(texto):\n",
        "  stemmer = nltk.stem.RSLPStemmer()\n",
        "  frasestratadas = []\n",
        "  for(palavras,emocao)in texto:\n",
        "      comsteming = [str(stemmer.stem(palavra))for palavra in palavras]\n",
        "      frasestratadas.append((comsteming,emocao))\n",
        "  return frasestratadas\n",
        "\n",
        "baseteste=aplicandostemmer(baseteste)\n",
        "basetreinamento=aplicandostemmer(basetreinamento)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuLhYsbN9WpA",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 5: Agora faremos uma lista com todas as palavras da nossa base.</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31LJoa239WO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def juntarpalavras(base):\n",
        "  todaspalavras=[]\n",
        "  for (palavras,emocao) in base:\n",
        "    todaspalavras.extend(palavras)\n",
        "  return todaspalavras\n",
        "def montarfrase(documento):\n",
        "  doc= set(documento)\n",
        "  caracteristicas = {}\n",
        "  for palavras in basetreinamento_palavras:\n",
        "    caracteristicas['%s'% palavras]= (palavras in doc)\n",
        "  return caracteristicas\n",
        "\n",
        "baseteste_palavras=juntarpalavras(baseteste)\n",
        "basetreinamento_palavras=juntarpalavras(basetreinamento)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR7F4vX1ANUg",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 6:Vamos agora montar a tabela com a quantidade de vezes que as palavras são executadas e alinha-la aos sentimentos rotulados.</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmgCNETPANEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def definirfrequencia(palavras):\n",
        "  palavras = nltk.FreqDist(palavras)\n",
        "  return palavras\n",
        "\n",
        "#frequencia = definirfrequencia(base_palavras)\n",
        "\n",
        "#Para uma unica frase :\n",
        "def definirpalavrasunicas(frequencia):\n",
        "  freq = frequencia.keys()\n",
        "  return freq\n",
        "\n",
        "frequencia_bteste = definirfrequencia(baseteste_palavras)\n",
        "frequencia_btreinamento = definirfrequencia(basetreinamento_palavras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvtFkMfZD-7w",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 7: Agora vamos extrair as palavras utilizadas para montar cada frase.</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNzVL1hFEEFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def montarfrase_teste(documento):\n",
        "  doc= set(documento)\n",
        "  caracteristicas = {}\n",
        "  for palavras in baseteste_palavras:\n",
        "    caracteristicas['%s'% palavras]= (palavras in doc)\n",
        "  return caracteristicas\n",
        "\n",
        "def montarfrase_treinamento(documento):\n",
        "  doc= set(documento)\n",
        "  caracteristicas = {}\n",
        "  for palavras in basetreinamento_palavras:\n",
        "    caracteristicas['%s'% palavras]= (palavras in doc)\n",
        "  return caracteristicas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDLoa06CF-lS",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 8: Montando a base de frases completa.</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO4rpPoyGF-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "base_teste_completa = nltk.classify.apply_features(montarfrase_teste,baseteste)\n",
        "base_treinamento_completa = nltk.classify.apply_features(montarfrase_treinamento,basetreinamento)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MWMKQdUdeRY",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 9: Inciando com o classificador</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpMlFB1ldeGi",
        "colab_type": "code",
        "outputId": "aa87f73b-5954-4706-db8f-9de9b76ed758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#classificando a base \n",
        "# O <i>train</i> é utilizado para treinar e assim montar a base \n",
        "classificador_treinamento=nltk.NaiveBayesClassifier.train(base_treinamento_completa)\n",
        "#classificador_teste=nltk.NaiveBayesClassifier.train(base_teste_completa)\n",
        "\n",
        "print(\"Para Conjunto de Treinamento:\")\n",
        "print(classificador_treinamento.show_most_informative_features(10))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Para Conjunto de Treinamento:\n",
            "Most Informative Features\n",
            "                   febre = True           Positi : Negati =     97.7 : 1.0\n",
            "                 amarela = True           Positi : Negati =     97.7 : 1.0\n",
            "                pimentel = True           Negati : Neutra =     65.0 : 1.0\n",
            "              calamidade = True           Negati : Neutra =     33.0 : 1.0\n",
            "                 justica = True           Negati : Positi =     30.3 : 1.0\n",
            "                      bb = True           Negati : Neutra =     26.3 : 1.0\n",
            "                   conta = True           Negati : Neutra =     26.3 : 1.0\n",
            "                fernando = True           Negati : Neutra =     25.0 : 1.0\n",
            "                educacao = True           Positi : Neutra =     23.7 : 1.0\n",
            "                  contra = True           Positi : Negati =     22.1 : 1.0\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjPdTMuUMvwk",
        "colab_type": "code",
        "outputId": "b7bff243-a00a-4479-e4cd-ad3e3881ab7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Para exibir as classes da base\n",
        "print(classificador_treinamento.labels())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Negative', 'Neutral', 'Positive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk39wvg8Uvj6",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 10: Medindo a acurácia do agente </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGCvQ-yQXa20",
        "colab_type": "text"
      },
      "source": [
        "Agora vamos testar a precisão do algoritmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_UACQ4sgRBr",
        "colab_type": "code",
        "outputId": "004e9063-f1c8-409e-9aee-9ea5e9b8d8d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(nltk.classify.accuracy(classificador_treinamento,base_teste_completa))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6143344709897611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViR3Puj1--U",
        "colab_type": "text"
      },
      "source": [
        "### 10.1 Matriz de confusão:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImBYpZuaflue",
        "colab_type": "code",
        "outputId": "27f831e0-5dd1-4dc3-8c6d-b31d954491fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#Matriz de Confusão\n",
        "from nltk.metrics import ConfusionMatrix\n",
        "esperado=[]\n",
        "previsto=[]\n",
        "for(frase,classe)in base_teste_completa:\n",
        "  resultado = classificador_treinamento.classify(frase)\n",
        "  previsto.append(resultado)\n",
        "  esperado.append(classe)\n",
        "  \n",
        "matriz=ConfusionMatrix(esperado,previsto)\n",
        "print(matriz)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         |  N     P |\n",
            "         |  e  N  o |\n",
            "         |  g  e  s |\n",
            "         |  a  u  i |\n",
            "         |  t  t  t |\n",
            "         |  i  r  i |\n",
            "         |  v  a  v |\n",
            "         |  e  l  e |\n",
            "---------+----------+\n",
            "Negative |<66>27  4 |\n",
            " Neutral | 11<72>15 |\n",
            "Positive |  6 50<42>|\n",
            "---------+----------+\n",
            "(row = reference; col = test)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8inDWC5p3EX",
        "colab_type": "text"
      },
      "source": [
        "<h2>Step 11: Realizando o teste </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTf-uCLwXbMJ",
        "colab_type": "code",
        "outputId": "ea258170-777f-46be-d556-fa75d7d16951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "import csv\n",
        "\n",
        "#Funções para frases unicas#\n",
        "def uniquestemmer(frase):\n",
        "  frasesteming = []\n",
        "  stemmer = nltk.stem.RSLPStemmer()\n",
        "  for(palavras) in frase.split():\n",
        "    comstem =[p for p in palavras.split()]\n",
        "    frasesteming.append(str(stemmer.stem(comstem[0])))\n",
        "  return frasesteming\n",
        "\n",
        "arquivo = '/content/bolsonaro.csv'\n",
        "\n",
        "with open(arquivo, 'r') as csvFile:\n",
        "  data_list = list(csv.reader(csvFile))\n",
        "  listaDeTupla = []\n",
        "  i = 0\n",
        "  lista = 0\n",
        "  for row in data_list:\n",
        "      listaDeTupla.append((row[0], row[1]))\n",
        "      lista = lista+1\n",
        "      i = i+1\n",
        "      if(i==50):\n",
        "          i = 0\n",
        "  csvFile.close()\n",
        "  \n",
        "# Abrindo o arquivo e salvando o resultado final\n",
        "file1 = open(\"arquivoFinal.txt\",\"w\")\n",
        "for l in listaDeTupla:\n",
        "  frase = uniquestemmer(l[1])\n",
        "  frase_montada=montarfrase(frase)\n",
        "\n",
        "  resultado = classificador_treinamento.classify(frase_montada)\n",
        "\n",
        "\n",
        "  file1.writelines(l[0] + \", \" + resultado + \", \" + l[1] + \"\\n\")\n",
        "\n",
        "file1.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-105664c020b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0marquivo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/bolsonaro.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marquivo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mlistaDeTupla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/bolsonaro.csv'"
          ]
        }
      ]
    }
  ]
}